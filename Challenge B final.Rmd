---
title: "Challenge B"
author: "Aymeric Maillard & Théo Le Zoualc'h"
date: "06/12/2017"
output:
  pdf_document: default
  html_document: default
---

https://github.com/aymericmrd/Challenge-B.git
We didn't succeed to import files on repository

#Task 1B - Predicting house prices in Ames, Iowa (continued)


```{r, include=FALSE}
#from Challenge A
load.libraries <- c('tidyverse', 'randomForest', 'knitr', 'rmarkdown', 'lmtest', 'caret', 'np', 'stringr', 'data.table', 'questionr')
install.lib <- load.libraries[!load.libraries %in% installed.packages()]
for(libs in install.lib) install.packages(libs, dependencies = TRUE)
sapply(load.libraries, require, character = TRUE)
```

```{r, include=FALSE}
#First we read datasets 
train <- read.csv(file = "/Users/aymericmrd/Documents/rprog/train.csv")
test <- read.csv(file = "/Users/aymericmrd/Documents/rprog/test.csv")
attach(train)
attach(test)
```

```{r missing data, include=FALSE}
# We exclude variables with too much missing observations
train %>% summarise_all(.funs = funs(sum(is.na(.)))) %>% gather(key = "feature", value = "missing.observations") %>% filter(missing.observations > 0)
remove.vars <- train %>% summarise_all(.funs = funs(sum(is.na(.)))) %>% gather(key = "feature", value = "missing.observations") %>% filter(missing.observations > 100) %>% select(feature) %>% unlist
train <- train %>% select(- one_of(remove.vars))
```

```{r, include=FALSE}
# We convert all character variables to factors
cat_var <- train %>% summarise_all(.funs = funs(is.character(.))) %>% gather(key = "feature", value = "is.chr") %>% filter(is.chr == TRUE) %>% select(feature) %>% unlist
train %>% mutate_at(.vars = cat_var, .funs = as.factor)
```

##Step 1:
We decide to choose the algorithm random forest. Random forest relies on decision trees which are gathering in order to form a stronger machine learning method. Its operations is based on the principle that the more trees, the more robust forest is. 

##Step 2:
  
```{r}
#We use the randomForest function replacing missing observations by median value. We use the model from the Challenge A)
fit.rf <- randomForest(SalePrice ~ MSZoning + LotArea + Neighborhood  + YearBuilt + OverallQual, data = train, na.action = na.roughfix)
summary(fit.rf)
```

##Step 3 : 

```{r, results = "hide"}
#We make predictions with the data test and the two regressions
forest.pred <- data.frame(SalePrice_predict = predict(fit.rf, data = test, type="response"))
fit.lm <- lm(SalePrice ~ MSZoning + LotArea + Neighborhood  + YearBuilt + OverallQual, data = train, na.action = na.roughfix)
lm.pred <- data.frame(SalePrice_predict = predict(fit.lm, data = test, type="response"))
```

```{r}
summary(abs(lm.pred - forest.pred))
summary(abs((lm.pred - forest.pred)/forest.pred))
```
There is on average a difference in absolute value of about 15365$. 
We can also see there is a difference of about 9.3% between these 2 predictions. 

#Task 2B - Overfitting in Machine Learning (continued)


```{r, include = FALSE}

##from Challenge A
rm(list = ls())

# True model : y = x^3 + epsilon
set.seed(1)
Nsim <- 150 
b <- c(0,1)
x0 <- rep(1, Nsim) 
x1 <- rnorm(n = Nsim)

X <- cbind(x0, x1^3) 
y.true <- X %*% b
eps <- rnorm(n = Nsim) 
y <- X %*% b + eps

df <- tbl_df(y[,1]) %>% rename(y = value) %>% bind_cols(tbl_df(x1)) %>% rename(x = value) %>% bind_cols(tbl_df(y.true[,1])) %>% rename(y.true = value) 
# the previous y and x are matrix and vector, I transform them into a dataframe to use the tidyverse
```


```{r, include = FALSE}

##from Challenge A
# Split sample into training and testing, 80/20
training.index <- createDataPartition(y = y, times = 1, p = 0.8) 
df <- df %>% mutate(which.data = ifelse(1:n() %in% training.index$Resample1, "training", "test"))

training <- df %>% filter(which.data == "training") 
test <- df %>% filter(which.data == "test")
```

##Step 1 - Estimate a low-flexibility local linear model on the training data.
Train local linear model y ~ x on training, using default low flexibility (high bandwidth)
```{r}
ll.fit.lowflex <- npreg(y ~ x, data = training, method = "ll", bws = 0.5)
summary(ll.fit.lowflex)
```

##Step 2 - Estimate a high-flexibility local linear model on the training data. 
Train local linear model y ~ x on training, using default low flexibility (high bandwidth)
```{r}
ll.fit.highflex <- npreg(y ~ x, data = training, method = "ll", bws = 0.01)
summary(ll.fit.highflex)
```

from Challenge A
```{r, include = FALSE}
df <- df %>% mutate(y.ll.lowflex = predict(object = ll.fit.lowflex, newdata = df), y.ll.highflex = predict(object = ll.fit.highflex, newdata = df))
training <- training %>% mutate(y.ll.lowflex = predict(object = ll.fit.lowflex, newdata = training), y.ll.highflex = predict(object = ll.fit.highflex, newdata = training))
```

##Step 3 - Plot the scatterplot of x-y, along with the predictions of ll.fit.lowflex and ll.fit.highflex, on only the training data.
from Challenge A
```{r}
ggplot(training) + geom_point(mapping = aes(x = x, y = y)) + 
  geom_line(mapping = aes(x = x, y = y.true)) + 
  geom_line(mapping = aes(x = x, y = y.ll.lowflex), color = "red") + 
  geom_line(mapping = aes(x = x, y = y.ll.highflex), color = "blue")
```

##Step 4 - Between the two models, which predictions are more variable? Which predictions have the least bias?
In the highflex model, we observe that the predictions are more variable/fluctuate.
Moreover we observe that it’s still the highflex model which has the smallest bias.

##Step 5 - Plot the scatterplot of x-y, along with the predictions of ll.fit.lowflex and ll.fit.highflex now using the test data.

```{r, include=FALSE}
##from Challenge A
df <- df %>% mutate(y.ll.lowflex = predict(object = ll.fit.lowflex, newdata = df), y.ll.highflex2 = predict(object = ll.fit.highflex, newdata = df))
test <- test %>% mutate(y.ll.lowflex = predict(object = ll.fit.lowflex, newdata = test), y.ll.highflex = predict(object = ll.fit.highflex, newdata = test))
```

from Challenge A
```{r}
ggplot(test) + geom_point(mapping = aes(x = x, y = y)) + 
  geom_line(mapping = aes(x = x, y = y.true)) + 
  geom_line(mapping = aes(x = x, y = y.ll.lowflex), color = "red") + 
  geom_line(mapping = aes(x = x, y = y.ll.highflex), color = "blue")
```
One more time, predictions are more variables in the highflex model..
Moreover, we observe that’s the lowflex which has the smallest bias now.

##Step 6 - Create a vector of bandwidth going from 0.01 to 0.5 with a step of 0.001
from Challenge A
```{r}
bw <- seq(0.01, 0.5, by = 0.001)
```

##Step 7 - Estimate a local linear model y ~ x on the training data with each bandwidth.
from Challenge A
```{r}
llbw.fit <- lapply(X = bw, FUN = function(bw) {npreg(y ~ x, training, method = "ll", bws = bw)})
```

##Step 8 - Compute for each bandwidth the MSE on the training data.
from Challenge A
```{r}
mse.training <- function(fit.model){
  predictions <- predict(object = fit.model, newdata = training)
  training %>% mutate(squared.error = (y - predictions)^2) %>% summarize(mse = mean(squared.error))
}
mse.train.results <- unlist(lapply(X = llbw.fit, FUN = mse.training))
```

##Step 9 - Compute for each bandwidth the MSE on the test data.
from Challenge A
```{r}
mse.test <- function(fit.model){
  predictions <- predict(object = fit.model, newdata = test)
  test %>% mutate(squared.error = (y - predictions)^2) %>% summarize(mse = mean(squared.error))
}
mse.test.results <- unlist(lapply(X = llbw.fit, FUN = mse.test))

```

##Step 10 - Step 10 - Draw on the same plot how the MSE on training data, and test data
from Challenge A
```{r}
mse.df <- tbl_df(data.frame(bandwidth = bw, mse.train = mse.train.results, mse.test = mse.test.results))
ggplot(mse.df) + 
  geom_line(mapping = aes(x = bandwidth, y = mse.train), color = "blue") +
  geom_line(mapping = aes(x = bandwidth, y = mse.test), color = "orange")
```

#Task 3B - Privacy regulation compliance in France

My computer is too slow to export task 3 in pdf
##Step 1 - Import the CNIL dataset from the Open Data Portal.
```{r}
CNIL <- read.csv("/Users/aymericmrd/Documents/rprog/Challenge/OpenCNIL_Organismes_avec_CIL_VD_20171204.csv",sep = ';')
```
##Step 2 - Show a (nice) table with the number of organizations that has nominated a CNIL per department.

```{r}
# We select the postal code
Dep <- data.frame(Dep = CNIL$Code_Postal)
#Then we select the department code
Dep <- str_sub(Dep, 1,2)
#We compute a table to know frequencies
Dep.companies <- as.data.frame(table(Dep))
colnames(Dep.companies) <- c("Department","Number of companies")
```

##Step 3 - Merge the information from the SIREN dataset into the CNIL data.
```{r}
#system.time(data.siren <- fread("/Users/aymericmrd/Documents/rprog/Challenge/sirc-17804_9075_14209_201710_L_M_20171101_030132835.csv", sep = ';', header = TRUE))

#We sort dates with decreasing order
#data.siren <- data.siren[order(DATEMAJ , decreasing = TRUE ),]

#We delete duplicated SIREN number and keep the most update
#data.siren <- subset(data.siren, FUN = !duplicated(data.siren[,1]))
#anyDuplicated(data.siren)

#We try to merge the two dataset by completing informations from the CNIL data with the "data.siren" dataset
#CNIL.SIREN <- merge(x=CNIL, y=data.siren, by.x = "Siren", by.y = "SIREN" , all.x=TRUE, sort = FALSE)
#attach(CNIL.SIREN)
```

##Step 4 - Plot the histogram of the size of the companies that nominated a CIL.
```{r}
#We select the data about the size of companies
#size.cil <- data.frame(CNIL.SIREN$LIBTEFEN)

#We create a table to know frequencies
#size.cil <- as.data.frame(table(size.cil))
#colnames(size.cil) <- c("Size","Number of companies")
```

#We arrange the look of the data
```{r}
#substi1 <- function(x) {gsub("[\xe9]","é",x) }
#substi2 <- function(x) {gsub("[\xe0]","à",x) }
#size.cil$Size <- substi1(size.cil$Size)
#size.cil$Size <- substi2(size.cil$Size)
```
#We try to compute the histogramm
```{r}
#barplot(size.cil$`Number of companies`, col = "green",
       # xlab="Size",
       # ylab="Number of companies", 
       # main="Size of the companies that nominated a CIL",
       # ylim=c(0,20000))
```

